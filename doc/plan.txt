TODO:       主要类结构
            场景管理
                场景树
                各种渲染对象属性和方法声明；
                    摄像机
                    网格
                    光源
                        frustum, shadow;
                    Decal
                    envprobe
                    irradiance volume
                对象更新；
            图元分发
                摄像机列表
                渲染图元对象定义；
                图元列表；
                    depth prepass
                    opaque
                    transparent
                    sprite? particle system?
                光源列表
                Decal 列表
                Cubemap 列表
                Irradiance volume 列表
                场景遍历，对象和图元分发
                初始化GL
            材质
                材质对象定义
                    RenderState Cache
                    标准 PBR 材质属性
            RenderTarget
                创建纹理和 RenderBuffer；注意创建的纹理和读取的纹理的关系；
            Shader架构
                Shader 预处理，加载，编译；
                    先用js字符串形式的shader源码测试；
                    实现 #include 机制；
                    以后再实现加载远程 shader 文件？
                命名规则
                Shader 输入、输出定义
                    thin g-buffer, for subsurface scattering, local reflection
                Uniform buffer对象封装
                Uniform buffer 定义：每帧，每View，每物体，每材质
                Uniform buffer 对象放在哪？shaderProgram 对象里？材质对象里？渲染器对象里？
                Uniform buffer 绑定
                渲染器中定义uniform buffer布局
                Vertex Attribute 解析
                Shader 代码结构
                    预置函数，预置变量定义和实现；
                Shader 是否也用缓存？或者为了简单起见，不用缓存了？
                渲染器中加载各种shader；
                    Shader文件和代码段key的命名规则
                    先实现 单色 shader, 测试绘制流程
                    再实现 depth prepass shader, 标准 PBR Shader
                Fix me: Fog 是在材质 Shader 中实现，还是用后期特效实现？
                    不透明物体，可用后期特效
                    半透明物体用材质 shader？
                    或者统一用材质 shader；
            简单Geometry生成、添加、绘制测试
                创建顶点缓冲；Vertex Attribute；Index buffer;
                Box，Sphere，Plane, 用于测试绘制；
                遍历图元列表，绘制
                    光源等非网格对象的 providePrimitive 也得调用，绘制调试图形；
                    Fustum culling; 
                    设置顶点Attribute pointer
                    * 如何在 depth prepass 时使用特殊的 shader？
                        不修改使用的shader；如果关闭了 color write，且 shader 中不使用 discard，则不会执行 shader，opengl 底层会使用一个默认的简单 shader 绘制
                        或者使用一组统一的 shader 来绘制；有镂空纹理的物体不绘制 depth prepass；
                        或者单独写一个带镂空纹理的 depth prepass shader，遇到有 alphaclip = true 的 PBR 材质，则使用这个 shader;
                            PBR 材质的贴图参数统一命名；材质中不带 shader, 使用统一的PBR 标准 shader 绘制；
                            自定义材质的某些贴图参数名称是否也要求统一命名？例如 opacity texture
                    Occlusion query?
                        在RenderItem上加一个是否需要Occlustion query的标志
                        将需要Occlusion query 的RenderItem 挑出来单放一个列表里
                        每帧先绘制不需要 quary 的（例如墙壁、地板、屋顶等），再绘制 query 的（房间中的细节物体）RenderItem 的包围盒
                        本帧 query，下帧才能拿结果，所以每帧都是根据上一帧包围盒的 query 结果绘制细节物体；
                当对象从场景移除时，释放显存资源；
                    加一个显式的 destory 接口？
                简单旋转动画；
                    使用 behavior 控制动画？
                    计时器对象；
                绘制视空间法线；检查背面剔除和法线是否正确；
                摄像机lookat控制？
                
            先实现简单的 forward shading
            直接光照
                添加光源到场景；
                    Shader 中取光源等 item 的函数
                    在 fragment shader 中变换光源到视空间？还是统一用世界空间计算？
                        变换像素的法线和位置到世界空间是否性能更好一些；可以避免将遍历到的每个光源、贴花等都变换到视空间
                PBR 光照计算
                    https://www.cnblogs.com/timlly/p/10631718.html
                多光源；
                测试各种光源类型；
                测试材质的各种参数；
                    TODO: emissive 和 opacity color
                阴影；
                    实现和测试设置 RenderTarget
                        实现和测试画到屏幕的二维矩形 shader
                        渲染到一张纹理，然后贴到场景中的物体表面；
                        屏幕矩形图元；或者屏幕矩形shader；
                        据说 FrameBufferObject 中切换 attached texture 要比切换 FrameBufferObject 快？
                            需要实现 FrameBufferObject 的灵活切换 attached texture 的方法？
                            暂时没必要；持各种观点的人都有，未必对性能影响那么大
                    先测试只有一个光源的阴影；动态光影；
                        实现 shadowmap shader；
                        给光源渲染 shadow map，在屏幕矩形上显示，用于调试
                        使用 depth texture 作为 Shadowmap，传入shader;
                        pbr shader 中计算光照时取样 shadowmap，
                            注意要使用 samplerShadow 类型
                        进一步软阴影；
                        测试不同类型光源的阴影；
                        实现点光源阴影？
                    Shadow map atlas; 
                        如何处理光源的 atlas rect size 变化的情况？还是一旦光源建立，就不允许改了？
                            重构一下，在 lightshadow 上记录 shadow rect 的尺寸，以及当前在 atlas 中的位置；
                            用户只能修改 rect 尺寸；当修改了尺寸后，dispatchobject 时发现与当前尺寸不一致了，就从旧列表中移除，添加到新列表；
                            能否将 lightshadow 和 atlas 位置解耦，将其对应关系以 map 的形式保存在 shadowmapAtlas 对象里？
                                renderer 每次更新 shadowmap 时都需要查询；
                    阴影的动态和静态更新逻辑
                        实现 Frustum culling?
                            有了此功能，才能判断光源中是否有活动的动态物体；
                            给光源生成 frustum
                        网格的包围球和包围盒
                            用包围球可能简单一些；无论怎么变换都是球；
                        静态光源和动态光源的区别：前者不会实时添加或删除，也不能移动或改颜色；后者是实时添加或删除的光源，可以移动、改属性；
                            但是两种类型的光源都可以更新阴影；
                            或者能否利用 unform buffer 的 subData 函数，只更新改变过的光源数据，使所有光源都能修改属性？
                        光源设置一个标志：是否需要更新阴影；维护一个本帧可见光源列表；
                            在光源对象 update 时判断: 如果光源运动了，设为 true；
                            在dispatchObject时，挑出运动的且可投影的物体放到一个列表，与所有当前可见的光源判断是否在其视野中；
                            每帧遍历可见光源且标志为 true，则更新shadowmap，然后将标志置 false;
                        测试物体包围球和光源 frustum 的相交判断；
                        优化：区分动态阴影和静态阴影的意义：
                            使用两张shadowmap，
                            静态shadowmap中只有标记为静态的物体；动态shadowmap中只有标记为动态的物体
                            静态物体的shadowmap可以只生成一次；
                            只有动态物体在光源内运动时，才将该物体绘制到动态shadowmap
                            问题：shader中每个光源都需要sample两张纹理
                        实现简单的相机控制；
                    如何处理带有镂空纹理的材质
                        * 也按照和 depth prepass 类似的方法处理
                    Mesh, light 对相机 Frustum 的剔除；
                    优化：应该通过 gl.BlitFrameBuffer 将静态阴影图集中的子图拷贝到动态阴影图集；
                        维护两个纹理，两个FBO：shadowmapAtlas 和 shadowmapCacheAtlas
                        shader 中只使用 shadowmapAtlas
                        一个标志：cacheDirty
                        当光源运动时
                            清 shadowmapAtlas
                            直接向 ShadowmapAtlas 中渲染静态和动态物体
                            置 cacheDirty = true
                        当光源不动时
                            置 cacheCopied = false;
                            如果 cacheDirty == true,
                                清 shadowmapCacheAtlas; 
                                渲染所有静态物体到 shadowmapCacheAtlas;
                                将 cache 拷贝到 shadowmapAtlas
                                置 cacheCopied = true;
                                置 cacheDirty = false
                            如果光源中有动态物体，则
                                如果 cacheCopied == false，拷贝；
                                向 shadowmapAtlas 中渲染动态物体（不清深度缓冲）

                    点光源的阴影；
                        怎样为点光源阴影申请图集子图？
                            需要向阴影图集中渲染六次；占用六个子图；
                            将列表中的六个元素都记录为该 lightShadow 对象
                            在 lightShadow 中使用一个列表来记录子图矩形？
                            对 shadowmap 分辨率做限制，不能使用太高分辨率的？

                        怎样在 Shader 中使用
                            由于点光源的变换矩阵不用完整传入，只传入一个中心点位置即可，
                                利用 worldMatrix 和 projMatrix 余下的总共 7 个 vec4 传入所有子图的矩形位置？
                            shader 中判断如果是点光源，需要计算像素处于哪个 frustum，获得 cubeface 编号；
                            根据 cubeface 编号计算视空间的三个轴vx, vy, vz;
                                posLightLocal = （像素位置 - 光源位置）;
                                posView.x = dot(posLightLocal, vx);
                                posView.y = dot(posLightLocal, vy);
                                posView.z = dot(posLightLocal, vz); // 实际上这三步可以通过直接取该轴对应的分量完成，简化运算
                                posProj = matShadowProj * posView;  // matShadowProj 是一个统一的矩形常量，可以在光源循环外创建；
                                posNDC = posProj / w;
                                uvw = posNDC 应用子图视口变换；

                        测试
                            做一个比较适合检查点光源投影的场景

            现在的 renderer 类代码有点长了 是否应该重构一下？
                将功能分散在 shadowmaprenderer, cubemaprenderer里？

            间接光照
                RenderTarget; 渲染到cubemap；
                    使用一个 2D Texture atlas? 还是使用 Texture Array？
                    因为 Cubemap 使用统一的尺寸，所以可以考虑使用 Texture Array
                    怎样渲染到 texture array?
                        使用 gl.framebufferTextureLayer
                    调试输出渲染结果；
                    渲染时应该保证足够远的远裁剪面距离；否则远处的物体无法渲到环境贴图上；
                    应该可以设置 envprobe 的背景颜色或天空盒；
                    尝试能否在 shader 中给 RenderTarget 贴图使用 linear 过滤？

                生成 envmap cube（64 x 64）
                    生成 mipmaps？如何进行卷积过滤？
                        封装若干个类干这个事，不要把功能都放在 clusteredForwardRenderer 里
                    diffuse
                        通过黎曼和生成 Diffuse 使用的低分辨率环境贴图，只需要一个mip level
                        参考：https://blog.csdn.net/i_dovelemon/article/details/79091105
                        能否进一步生成 Ambient Cube 或 SH ？
                        取样时注意边缘像素；
                    specular
                        通过 importance sampling  生成 mipmap，每个 level 对应一个 Roughness 下的 LD 项
                        DFG 项是一个预渲染的通用贴图，可以直接加载使用；
                        参考：https://blog.csdn.net/i_dovelemon/article/details/79598921
                            https://blog.csdn.net/i_dovelemon/article/details/79251920

                    diffuse 和 specular 都用同一个 texture2darray；
                        diffuse 放在分辨率较低的一个 level 里
                        specular 放在其他 level 里
                        64x64，7 mip levels
                        0, 1, 2, 3 : specular
                        4: 4x4, diffuse；或者用 1x1 ambient cube? 取样时算法简单一些
                    能否/是否有必要多次渲染envmap，模拟光线多次反射的机制？
                    EnvProbe 多遍 Bake
                image based lighting
                    shader 中使用的时候，在取样边缘点时从其它面取样过滤？能否预先处理一下 cubemap，将边缘处扩展一下，填充其它面的对应像素？

                    多个 envprobe 的混合
                        权重：距离和尺寸？
                    分别使用 diffuse 和 specular cubemap

                    使用HDR Cubemaps？
                        使用浮点格式 cubemap;
                            Firefox 不支持 RGB float 渲染输出
                            或者向 cubemap 中输出除以一个亮度系数的颜色，在应用时再乘回来？
                        渲染cubemap时，不做 tonemapping；
                        渲染cubemap时，不使用 MRT

                // 生成 irradiance volume？或者尝试用low mipmap envmap cube 做间接光照？
                //    为每个 envmap probe 生成一个 shadowmap，用以剔除影响范围外的物体
                //        该 shadowmap 中只绘制开启了 occlusion query 的静态物体；这样房间内的细节物体的背向 probe 中心点的面不会被剔除，也可以有环境光照。

            SSAO，屏幕空间反射, 屏幕空间 GI？；
                需要输出一个 thin G-buffer；在 Depth prepass 时输出？还是使用MRT，在绘制不透明时输出？参考一下DOOM
                    深度：能否直接使用 depth buffer? 需要恢复出屏幕空间 z
                    normal                                  R16G16
                    specular color (F)  roughness           RGBA8
                需要将主画面输出改为到一个 MRT 上？
                    注意将各 shader 输出也改为 MRT 的
                SSAO shader;

                    改为不是立刻混合到原画面，而是在最后和 SSR、Fog 等一起混合？

                SSR
                    需要保留上一帧画面和速度图？
                        在 DepthPrepass 时生成速度图？
                        上一帧画面必须是应用了Bloom 和 Tonemapping 之前的；但是包括SSAO, SSR，Fog，半透明；
                        半透明只能在前三个特效完成之后绘制；

                        调整 SSR 的不透明度：只使用视角系数和屏幕边界系数，不考虑材质 specular
                    组合结果 Pass：
                        以本帧画面，SSR 画面为输入，做雾效，组合，
                    无法使用屏幕空间反射的像素，使用该像素所属 Cluster 的环境反射贴图？
                        将环境反射贴图的操作推迟到这步后期中进行？不放到 SSR shader 中，避免 cubemap 反射结果被模糊？
                        需要传入法线，镜面反射和粗糙度贴图
                        根据 SSR 结果图的 alpha 通道混合 SSR 结果颜色和 cubemap 反射颜色；需要乘以表面本身的镜面反射颜色？
                        根据视线与法线夹角、镜面反射颜色，求菲涅尔强度计算反射的整体混合系数？
                        改为通过颜色相加的方式混合？因为应该是 Diffuse + specular
                    
                    SSAO 作为 specular occlusion

                    SSR Blur 过强了问题
                        bilateral filter 是否应该也考虑法线？

                    TODO: 对比两种 SSR 的 shader 的效果和性能
                        Unity 5 的
                            优化更好一些，但是不太科学；使用的 roughness 计算反射的强度；
                            最后整合效果时通过 roughness 决定 SSR 的模糊半径
                        Babylon.js 中的http://imanolfotia.com/blog/update/2017/03/11/ScreenSpaceReflections.html
                            比较简单，好理解一些，
                            在 raymarch 时根据表面粗糙度对取样方向加了一个扰动；

                        其他参考资料：
                            https://sakibsaikia.github.io/graphics/2016/12/26/Screen-Space-Reflection-in-Killing-Floor-2.html#applying-reflections

                    SSAO blur 效果优化
                        噪声纹理是否改为使用蓝噪声？
                        
            最终输出：
                做 Bloom 和 Tone mapping，向主屏幕输出
                作为一个后期特效。这样保证在之前的整个渲染流程都是 HDR 线性空间的。
                Tone mapping shader 同时输出画面中高亮度部分和 tone mapping 结果？
                default pbr shader 中不再做 tonemapping；

            性能：检查渲染 cubemap 用了多长时间？能否优化？
            显式FPS的功能；SSR 是否太耗性能了？性能计时器，统计各过程用了多少毫秒？
                合并 SSR 的 shader 在低端显卡上十分耗性能，检查原因。
                    原因：笔记本的浏览器使用的是核显，不是独显。

            Subsurface scattering
                参考 Khronos Group glTF Viewer; Blender;
                使用神海近似的实现方式，还是 screen space subsurface scattering?
                预先生成 subsurface scattering BRDF 纹理
                    纵轴是曲度，横轴是NdotL
                    Fix me: 如何将 subsurface 颜色 例如 肤色 或 雪色 放进去？还是将该颜色提取出来，作为材质参数？
                        是否可以简化一下生成的过程；
                            BRDF 纹理中只记录次表面反射颜色强度。近似对 ndotl 卷积的结果？
                需要计算表面的弯曲度；曲度越大，SS 越明显
                绘制时：
                    用 ndotl， curvature 和材质次表面反射系数为 UV 和系数取 BRDF 纹理，获得次表面反射强度 subsurfaceStrength
                    Fix me: 次表面反射需要深度和强度两个参数？或者二者有无对应关系？深度越深，强度越强？
                        次表面反射系数同时影响次表面反射的范围和强度？
                    尝试: 结果 = mix(vec3(ndotl), u_material.subsurfaceColor * subsurfaceStrength, u_material.subsurface)
                    Fix me: 阴影怎么处理？从参考资料里找一下解决方案
                是否应该用更科学的方式生成 BRDF 纹理？
                    先计算 ndotl，然后再用一个 pass，根据 curvature 求模糊半径，对 ndotl 做卷积，得到次表面反射的强度 ?

            cubemap 边缘 filter
                写一个 shader；传入 cubemap 尺寸；对边界像素，使它们和邻接面的对应像素颜色一致。
                是否可以通过调整 cubemap 各面的排列方式，减少需要处理的边界，减少失真？
                    例如，将水平四个面按相邻顺序排列？
                    渲染时和取纹理时都得对应修改；
                    为了避免把现在的功能搞乱，还是先不调整了，直接每个面都统一处理边缘吧。
                    Fix me: 即使 fix edge 了，在绘制时做双线过滤仍然会取样到非邻接面的像素，导致有接缝
                    或者考虑不用 cubemap，使用全景图形式？
                    * 或者不再把六张图排到一张贴图里，而是分开，占用 texturearray 的六个 layer？
                    webgl 什么时候才能支持 cubmap array =.=

            加载贴图
                sampler state
                贴图的属性
                贴图的加载和绑定
                加载完成事件？
                加载后拷贝内容到显存的操作；
                测试加载贴图；
                Texture Cache;
                加载完贴图再生成 environment probe；模型也是
                    等场景中的所有模型贴图都加载完了，再将 Scene 赋给 Renderer？

            场景天空盒？
                skybox shader
                创建和加载 cubemap 的功能；实现 TextureCube
                绘制场景时最先绘制天空盒；
                    Fix me: 是否应该将天空盒放到 RenderContext 里，在 FetchRenderObjects 时从 scene 里取出？
                更新 cubemap 时，也绘制一下天空盒；
                HDR Cubemap 工具：https://matheowis.github.io/HDRI-to-CubeMap/
                HDR 资源：https://hdrihaven.com/hdris/

            GLTFLoader
                从 Blender 导出测试用的模型
                先直接引用 minimal gltf loader? 或者参考Khronos Group glTF Viewer
                GLTF JSON Schema 转为 typescript interface:
                    // generated by https://github.com/robertlong/gltf-typescript-generator
                    // npm install -g gltf-typescript-generator
                    // download khronos gltf json schema from github and host it
                    // run this command in windows powershell(administrator)
                    // gltf-typescript-generator ./gltf.ts http://127.0.0.1:5500/specification/2.0/schema/gltf.schema.json
                    // may need run 'set-ExecutionPolicy RemoteSigned first' to all[A] to allow npm to run scripts

                读取mesh, material, texture
                File Cache

                Fix me: 现在的gltfAsset get()返回的是 promise 对象；是否应该改为在加载时取得所有buffer和image，然后 get 时直接返回 buffer 和 image 对象？
                    或者保留这个机制，但是在解析和创建 scene 对象时就得按异步处理；

            Dithered soft shadow?
                使用一个 blue noise dither texture；在做 shadowmap 取样时根据像素屏幕坐标取 dither 偏移量，应用到 shadowmap uv 上？
                或者使用程序生成的 noise texture?
                使用 blue noise 或 halton sequence？
                效果不太好；
                    改为使用 blue noise 纹理，扩大取样点数量？
                    或者使用多采样 PCF？
                    参考 Babylon.js src\Shaders\ShadersInclude\shadowsFragmentFunctions.fx computeShadowWithPCF3 函数？
                    https://mynameismjp.wordpress.com/2013/09/10/shadow-maps/
                    https://github.com/TheRealMJP/Shadows


            文件加载机制
                使用Promise, async, await
                参考 https://github.com/bwasty/gltf-loader-ts
                FileLoader
                文件加载管理器
                    类似于 Pixi.js 的做法，一次提交批量要加载的文件；等所有文件加载成功后，调用一个 onLoad 函数
                    在该函数中再创建 scene 并赋值给 renderer
                    加载关卡资源 -> onLoad 创建 scene 中的对象 -> 传给 renderer

                    能否利用 Promise.all？

            Cache?
                将各种类型的硬件资源cache分开？便于提升cache查找速度？且可以针对不同类型的资源分别实现清除逻辑

            从读取出的 gtlf 数据生成图元、mesh 的逻辑

                Geometry Cache
                    所有从 gltf 文件加载的 geometry，统一用文件名 + 网格名生成一个key，放在 cache 中；多个 mesh 共享之；
                        注意这种 geometry 要标一下 incache，在对象 release 时避免释放它；由cache统一释放；
                Texture cache
                    用纹理文件 url 作为 key

                材质
                    shader中应该改为将 baseColor 和 baseColorMap 相乘？
                    支持法线贴图？
                        没有法线贴图时的处理？
                        顶点没有 tangent 时的处理？
                        顶点有和没有 tangent 使用不同的 shader 预编译分支？
                        如果没有 tangent, 则使用 http://hacksoflife.blogspot.ch/2009/11/per-pixel-tangent-space-normal-mapping.html 的方法在 pixel shader 中变换光源到视空间？还是统一用世界空间计算？
                        参考：  Khronos group gltf sampler viewer: src\shaders\pbr.frag
                                Three.js: examples\jsm\nodes\misc\NormalMapNode.js
                    * 光滑的物体似乎环境反射过于清晰了问题？

                Object3D 更新变换时使用分开的 SRT？
                    使用 quaterion 表示旋转

                测试加载绘制 gltf 模型
                    下载一些官方的示例模型测试；
                    支持metallicRoughtness贴图；

                读取light, decal, envprobe, irradiance volume;

            性能分析
                网页加载很慢的原因：shader编译很慢；

            骨骼皮肤动画
                Skin shader
                    skin matrix
                    skin normal matrix
                        仿照 Three.js 的做法，使用 skinMatrix * vec4(n, 0)？这样简单一点：
                        src\renderers\shaders\ShaderChunk\skinnormal_vertex.glsl.js

                        而 gltf-sample-viewer 中传入每个 joint 的 normalmatrix，略复杂：
                        src\shaders\animation.glsl

                    *** depth prepass, shadow skin shader.
                    
                SkinMesh类
                Update joint matrices and pass in uniforms

                绘制 SkinMesh 时，需要使用 skin shader
                    或者改成动态分支，可以简单一点，不用编译多份shader
                
                从 glTF 加载：skin 和 animation
                动画插值器；
                动画数据对象

                测试程序
                    加载带骨骼皮肤动画的模型
                    测试动画的播放
                    同时控制多个模型的动画播放
                    测试将动画模型放到场景中
                        场景定义动画模型位置

            绘制调试用的包围盒和包围球
                单位盒和单位球，边线模式图元
                在 RenderItems 时绘制？还是单独设立一个 pass？
                调试骨骼皮肤模型的包围球


            使用 HDR 环境贴图
                加载 hdr 贴图文件
                在 shader 中区分 HDR 纹理格式：RGBE 解析；
                测试；

            将环境反射 probe 和 irradiacne probe 分开
                可以提高 irradiance probe 的数量，同时避免占用过多显存
                使用 Ambient Cube，而不是 2x2 的环境贴图；可以降低 shader 复杂度；
                    单生成一个 1x1 的 texture array
                    为每个 irradiance probe 渲染 cubemap
                    将渲染好的 envmap 做 diffuse filter 输出到此 texture array

                    *** 添加一个 irradiance filter shader，可以直接用每个面的方向向量作为主卷积方向了；
                    *** 在 default pbr shader 中，按照 half life 2 的方式混合 （需要做三次采样），而不是按 cubemap 采样一次；
                    将渲染 cubemap 里相同的代码合并一下；

                注意：
                    先 update irradiance probes, 再 update envmaps；
                    irradiance probes 做多次反弹，envmaps 就不用了
                    生成 reflect map 时需要应用 irradiance probes
                    Fix me: irradiance probe 附近的面会变暗，什么原因？

            后期特效开启、关闭的控制；
                SSAO，SSR
                
            Irradiance probe 加一个亮度系数，补偿生成时由于数量较少造成的昏暗；
                生成时加系数，还是绘制时加系数？

            Blender python 脚本
                补充光源属性到 gltf 的 extra 中
                从 Blender 导出 Irradiance Volume 到 gltf；从 gltf 读取 Irradiance Volume，添加 probes 到场景；
                    ** 导出 Irradiance voluem 和 reflection probe 的更多属性：影响半径等；
                    渲染时，通过节点缩放乘以影响半径得到最终的影响半径；
                        ## Reflect probe 的矫正体？实现 Parallax corrected cubemap? 不紧急
                        ## 需要将矫正体空间变换矩阵加入uniform buffer
                补充材质属性到 gltf 的 extra 中
                    次表面反射参数；高光强度；

-------------------------- 进行到这里了 ---------------------------

            动画控制
                动画状态机；
                    调试动画状态机；
                    通过 JSON 创建状态机；
                更多 make 动画？
                优化动画性能：不每帧更新包围球？预处理 SkinMesh 时计算一个最大包围球？
                    经过实测，是否更新包围球对性能影响不大
                动画 Mixer？不着急实现
                弹簧控制器
                    用于R摇

            尝试一下简版次表面效果
                gltf-Model-Viewer中的方法
                https://www.alanzucconi.com/2017/08/30/fast-subsurface-scattering-2/
                经过测试，效果并不太好
                自定义次表面材质的反射模型；pre-integrated；只在明暗交界的部分修改颜色；
                    阴影 bias 增大；阴影内部不使用次表面反射；

            支持材质自定义 Shader？
                不紧急
                非物理材质比如卡通材质
                粒子系统，特效等；
                Shader Cache 机制
                    Cache key: shader code key, features;
                    程序的最开始，需要把 shader code 注册到全局列表

            ** 半透明物体的绘制？
                需要由远到近排序？按照物体中心点；
                半透明shader中应该应用 reflection probe, 而不是 diffuse probe?
                    否则玻璃等物体就没有环境反射了
                    在 default_pbr shader 中通过材质不透明度判断？
                    或者单写一个半透明的 shader？
                    应该根据不透明度决定用多少 diffuse probe 和 reflection probe

            优化 shader 效率？
                目标 60 fps on GTX1660

            绘制光源和 envProbe 的调试图元
                差光源的；

            平行光的处理
                如果平行光指定了半径和距离，则以外的部分不应产生光照？
                    目前光范围边缘会有个缝，漏光；可能是阴影图集采样不准确引起的

            ## 阴影继续优化：柔化边缘(不着急)
                方差阴影？或者加入线性插值？
                    取四点PCF，然后做线性插值？

            解决屏幕空间反射使用上一帧画面导致反射滞后现象
                ##不是很紧急
                比较复杂，需要生成速度图

            更多的后期特效：
                光晕
                Height fog；包含 noise?
                FXAA
                转场特效：渐入渐出，黑屏白屏；
                    能否集成在 tonemapping 里？就不用再多一次绘制和一个RT了
                    是否应该放在UI里？因为希望UI一起渐入渐出；
                色调调整：通过颜色 LUT
                    能否也集成在 tonemapping 里？
                景深；不着急做

            相机动画；
                从 Blender 导出；
                能否导出相机的视野属性动画？
                如果视野发生了变化，则 Cluster 也得更新；

            有法线贴图时法线扭曲问题
                可能是通过梯度计算切向空间不准确引起的？
                支持模型中的切向数据；
                    shader 中 u_object 加一个标志：是否具有切线数据
                    blender 导出 gltf 时勾选导出切线

            ** GameScene 管理
                参考 Phaser 和 PIXI.js？
                H-Game Demo 场景管理和简单逻辑；
            
            资源加载器
                资源列表和资源计数？
                参考类似 PIXI.js 的机制？
                    输入一个要加载的资源 url 列表？在 onload 函数中回调一个加载完的资源数据 map？
                    能否通过 promise 的方式返回？
                    所有资源加载完后再开始逻辑循环？
                    切换场景时清空资源缓存，更新要加载的资源列表，调用 load 方法?
                考虑统一使用 Promise.all 实现？
                    需要将不同的资源分类；Typescript Promise.all 仅支持列表中元素为同一类型；
                    根据文件扩展名放到不同的 promise 列表里？

            优化 tsm 库？

        大场景相关

            制作模块化的大一点的场景；
                FPS：模块化类 DOOM 室内场景, 狭窄一些；Local point lights; 
                    导出，测试 clustered, instancing, occlusion culling 等
                    Blender 的 Reflection probe 中加一个最远可视距离属性；

                Action: 日式城堡，室外+室内，宽阔一些 或横板？夜间；无月光；雾；Local point lights：灯烛，火把；

            经测试，需要注意：
                1、blender 中的细节物体必须 apply 所有修改器后再复制，否则无法共享网格数据，导致无法 instancing
                2、锥形光的阴影bias需要取很小的值（目前取默认值-0.0005），否则阴影画不出来

            Instancing
                GLTF中共享网格的节点设为用 Instancing
                注意 vertex shader 中不要添加无用的 vertex 输入，否则 instancing 会出问题
                是否应该再整理一下从 gltf 读取 instanced mesh 的代码；目前有点乱；

                什么时候更新 instance 矩阵数组？
                    如果是gltf静态instance，应该只需要更新一次；
                Instancing shader
                    can use in mat4 in vertex shader for attribute input;
                    Cache shaders by key: shader file pathes and macros or features?
                InstanceMesh 怎样做 frustum culling?
                    Bounding box of instances?
                    需要在 Blender 中手动对 Instancing 的物体分组，每个组使用一个统一的包围盒？
                        每一组的 instancing 物体放到一个父物体下？
                    或者在加载 gltf 后按照一定的 BVH 自动对 Instancing 的物体分块？
                        四叉树或八叉树，或最简单的 Cell
                        将生成 instancing 网格的操作放在这一步，而不是加载 gltf 时？
                Occlusion query
                    用 instanced 方式绘制包围盒
                动态的 instancing 物体怎么处理
                    更新矩阵；包围盒？occlusion query?
                    ** 暂时不支持动态 instancing
            
            物体是否做包围球检测的控制标志？ 
            
            测试 Occlusion query?
                区分哪些网格是 occluder，哪些网格需要 occlusion query；使用 Custom Property 标志？
                    在 blender 中给物体加一个自定义属性，occlustionQuery
                拷贝 occlusion 相关属性的脚本；
                测试Demo，调试
                    普通mesh的occlusion query
                    instancedMesh的occlusion query

            ## Decals
                由于不太好从 Blender 导出 Decal 在图集中的纹理坐标，暂时不着急实现

            Clustered 光源、envmap、irradiance volume
            当视场角等投影参数变化时，更新 Cluster 的逻辑；
            继续优化 CPU 端的 Cluster 检测？

            xx 非 Cluster 时也做一下光源等的视见体剔除，以加快 reflect probe 和 irradiance probe 的生成速度?
                暂时没有必要，因为 env probe 的贴图尺寸都很小；可能做了还没有不做快

            户外阴影方案
                Cascaded shadow map? 
                或类似的简化方案：指定一个平行光作为日光，近景用跟随相机走的动态 shadowmap，远景过度到静态 shadowmap

            particle system; sprite;
                使用 GPU 计算 particle: transform feedback
                    https://gpfault.net/posts/webgl2-particles.txt.html
                粒子物理：可以通过深度图获得场景位置，在 GPU 计算碰撞？https://nullprogram.com/webgl-particles/

            考虑技能特效等怎么实现；
                刀光、击中特效等
                模型 + 自定义 shader；UV 和颜色动画；
                无法从 blender 中导出；
                    √ 通过 json 定义动画关键帧实现？
                        每个特效是一个单独的 gltf 文件；另附加一个 json 文件，记录该 gltf 中节点材质颜色和 UV 动画关键帧；
                    × 或者能否通过 blender 对象的自定义属性记录？需要支持关键帧数组；

            ECS 架构
                从 GLTF 加载组件信息？
                    读取 object 的自定义属性：组件列表和组件属性？或者 prefab 名称？
                    使用 json 定义 object prefab 对象；

            Volume Rendering?
                带高度渐变的全局雾；
                SDF；
                体积雾；
                    体积雾带光照，并取样 shadowmap？
                    Raymarch

        物理系统
            考虑使用 Cannon.es: https://github.com/pmndrs/cannon-es
            带物理的第一人称控制：https://github.com/mrdoob/three.js/blob/master/examples/js/controls/PointerLockControls.js
            从 gltf 读取物理碰撞体到 cannon.js:
                尽量只使用 box, sphere, cylinder 等简单物体；
                在 Blender 中使用单位尺寸的物体；通过缩放控制形状和尺寸；给一个自定义属性表明是物理碰撞体，以及形状类别
                在 gltfSceneBuilder 中，当读取到此类物体时，设置其为不可见，并创建为物理碰撞体类型对象
                写一个物理场景生成器，遍历 scene 的节点，当节点是物理碰撞体时，根据其形状和变换信息，生成 Cannon.js 刚体对象
